{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import implementations\n",
    "import helpers\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=False)\n",
    "\n",
    "print(y.shape)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and standarization of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15\n",
    "all_tx, all_y = helpers.build_data(y, tX, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tX.shape[1]):\n",
    "    tX[:,i] = np.where(tX[:,i]==-999, 0, tX[:,i])\n",
    "clean_tX = tX\n",
    "std_tX = helpers.standardize(clean_tX)\n",
    "row = std_tX.shape[0]\n",
    "model_data = np.c_[np.ones(row), std_tX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do your thing crazy machine learning thing here :) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(model_data.shape[1])\n",
    "gamma = 1e-5\n",
    "max_iters = 300\n",
    "lambda_ = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.42582133e-04  4.57940325e-04 -9.96725163e-04 -3.99962496e-05\n",
      "  5.42154398e-04  6.43019035e-04  6.42776725e-04 -5.37168543e-04\n",
      "  3.76704474e-05 -4.56435688e-05  4.29879220e-04 -5.54763717e-04\n",
      "  7.68814041e-04  6.29944409e-04  6.65892415e-04 -2.71402858e-06\n",
      " -1.25345828e-05 -9.18166544e-05  4.22957551e-06  1.17292500e-05\n",
      "  6.10202078e-05  2.11715494e-05  3.79780674e-04  3.74167525e-04\n",
      "  4.64293763e-04  2.04936832e-07 -2.33217894e-06  3.10141357e-04\n",
      " -2.51986940e-09 -1.03435792e-05  3.75874132e-04] 0.4979467538968276\n",
      "0.671956\n"
     ]
    }
   ],
   "source": [
    "w, loss = implementations.least_square_GD(y, model_data, initial_w, max_iters, gamma)\n",
    "print(w, loss)\n",
    "tmp = y == predict_labels(w, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.19394203e-04  7.82164021e-04 -1.09077474e-03  5.17227900e-05\n",
      "  4.69404902e-04  5.04688779e-04  6.28236021e-04 -3.09028740e-04\n",
      "  5.68516886e-05  1.50797108e-04  5.67210974e-04 -4.11190619e-04\n",
      "  7.12963310e-04  6.17283916e-04  8.13399583e-04  3.34120865e-04\n",
      " -6.68261890e-05  1.04988600e-04  2.37732359e-04  1.11690916e-05\n",
      " -1.38476202e-04  4.38634627e-04  5.18182376e-04  3.45644647e-04\n",
      "  4.11774279e-04  3.78363273e-04 -8.76962731e-05  5.42526981e-04\n",
      "  7.93832683e-05  1.84185641e-04  4.59959209e-04] 0.49432945882136825\n",
      "0.663212\n"
     ]
    }
   ],
   "source": [
    "w, loss = implementations.least_square_SGD(y, model_data, initial_w, max_iters, gamma)\n",
    "print(w, loss)\n",
    "tmp = y == predict_labels(w, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.14664000e-01  3.16555434e-02 -2.47975107e-01 -2.64962619e-01\n",
      " -2.63631352e-02 -1.41546894e-02  1.15765041e-01 -1.66187067e-02\n",
      "  2.67801683e-01 -1.74727785e-03 -3.08655587e+02 -1.84459194e-01\n",
      "  1.20570403e-01  1.01119820e-01  5.99694592e+01 -1.06758125e-03\n",
      " -9.58517517e-04  5.91412114e+01 -2.77847718e-04  2.44146285e-03\n",
      "  1.00653641e-01  8.61823091e-04 -5.88988313e-02  1.42093190e-02\n",
      "  1.59469823e-01  4.91068259e-04  1.63473582e-05  3.59518595e-02\n",
      "  1.29382257e-03 -1.90414844e-03  2.61183987e+02] 0.3390159873413056\n",
      "0.746532\n"
     ]
    }
   ],
   "source": [
    "w, loss = implementations.least_square(y, model_data)\n",
    "print(w, loss)\n",
    "tmp = y == predict_labels(w, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.08494118e-01  3.28116242e-02 -2.36157575e-01 -2.25274261e-01\n",
      "  1.53620080e-03  1.07940213e-02  1.01899220e-01 -1.50094874e-02\n",
      "  2.35840840e-01 -1.32302307e-02 -2.29573914e-02 -1.57943244e-01\n",
      "  1.21023606e-01  9.66448967e-02  1.79454039e-01 -1.08368896e-03\n",
      " -1.17055057e-03  2.35837558e-01 -2.31644344e-04  2.48843452e-03\n",
      "  8.16230278e-02  1.05921596e-03 -5.49661620e-02 -1.05542719e-02\n",
      "  6.81601544e-02  3.95804156e-04  1.32109035e-04 -1.30454037e-02\n",
      "  1.34942125e-03 -1.72278843e-03 -1.21224967e-01] 0.3396570615485826\n",
      "0.744988\n"
     ]
    }
   ],
   "source": [
    "w, loss = implementations.ridge_regression(y, model_data, lambda_)\n",
    "print(w, loss)\n",
    "tmp = y == predict_labels(w, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.17925941e-03  4.79628821e-05 -8.58175023e-04 -2.12285577e-04\n",
      "  4.21840381e-04  4.57573995e-04  5.80879197e-04 -5.23352903e-04\n",
      " -2.20865473e-04  3.58853396e-04  3.26837146e-04 -5.86804166e-04\n",
      "  4.39237403e-04  6.51936971e-04  5.83424793e-04 -3.76619731e-04\n",
      " -5.61404063e-05 -1.63850281e-04 -2.16454740e-04  3.41765569e-04\n",
      "  6.61868338e-05 -4.44427397e-05  3.08936108e-04  1.11363277e-04\n",
      "  3.65007119e-04 -2.55397248e-04 -4.21693329e-04  2.31343831e-04\n",
      " -2.49013591e-04 -3.69898746e-05  2.89306756e-04] 0.682363747329534\n",
      "0.67694\n"
     ]
    }
   ],
   "source": [
    "w_final, loss_final = implementations.logistic_regression(y, model_data, initial_w, max_iters, gamma)\n",
    "print(w_final,loss_final)\n",
    "tmp = y == predict_labels(w_final, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.55901920e-03  4.06859638e-04 -1.11010165e-03  2.97820283e-05\n",
      "  9.50276030e-04  5.11385130e-04  6.79494524e-04 -3.22448691e-04\n",
      "  6.25354561e-05 -2.28305101e-04  8.26350767e-04 -4.89743726e-04\n",
      "  1.02432316e-03  6.90856803e-04  8.32420697e-04  2.19809990e-04\n",
      "  2.60435185e-04  6.22610750e-05 -1.07709752e-04 -2.74061628e-04\n",
      "  5.88903421e-04 -1.20398205e-04  6.29145442e-04  4.44140874e-04\n",
      "  9.83290007e-04  3.19506048e-04 -5.75180189e-05  6.44749720e-04\n",
      " -2.37928290e-04 -7.80449000e-05  7.71138834e-04] -0.6973119398506299\n",
      "0.667276\n"
     ]
    }
   ],
   "source": [
    "w_final, loss_final = implementations.reg_logistic_regression(y, model_data, initial_w, max_iters, gamma, lambda_)\n",
    "print(w_final,loss_final)\n",
    "tmp = y == predict_labels(w_final, model_data)\n",
    "print(np.count_nonzero(tmp == 1)/len(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main code we submit, above is just test with a basic cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best Gamma and Lambda_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambdas = np.logspace(-2, 0,num=1)\n",
    "k_fold = 5\n",
    "seed = 0\n",
    "max_iters = 100\n",
    "gamma = 1e-5\n",
    "\n",
    "wanted_index = 0\n",
    "\n",
    "tx_wanted = all_tx[wanted_index]\n",
    "y_wanted = all_y[wanted_index]\n",
    "\n",
    "k_indices = helpers.build_k_indices(y_wanted, k_fold, seed)\n",
    "initial_w = np.zeros(tx_wanted.shape[1])\n",
    "\n",
    "arr_pred_tr = []\n",
    "arr_pred_te = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    pred_tr_tmp = []\n",
    "    pred_te_tmp = []\n",
    "    for k in range(k_fold):\n",
    "        pred_tr, pred_te = helpers.cross_validation(y_wanted, tx_wanted, initial_w, max_iters, gamma, lambda_, k_indices, k)\n",
    "        pred_tr_tmp.append(pred_tr)\n",
    "        pred_te_tmp.append(pred_te)\n",
    "    arr_pred_tr.append(np.mean(pred_tr_tmp))\n",
    "    arr_pred_te.append(np.mean(pred_te_tmp))\n",
    "    \n",
    "maxIndex_tr = np.argmax(arr_pred_tr)\n",
    "maxIndex_te = np.argmax(arr_pred_te)\n",
    "    \n",
    "print(max(arr_pred_tr), lambdas[maxIndex_tr])\n",
    "print(max(arr_pred_te), lambdas[maxIndex_te])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e-5\n",
    "max_iters = 300\n",
    "all_w = []\n",
    "all_pred = []\n",
    "for tx, y_ in zip(all_tx, all_y):\n",
    "    initial_w = np.zeros(tx.shape[1])\n",
    "    w_final, _ = implementations.logistic_regression(y_, tx, initial_w, max_iters, gamma)\n",
    "    all_pred.append(np.count_nonzero((y_ == predict_labels(w_final, tx)) == 1)/len(y_))\n",
    "    all_w.append(w_final)\n",
    "    \n",
    "weights = all_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tx_te, all_id_te = helpers.build_data(ids_test, tX_test, 0.15)\n",
    "y_pred = helpers.pred_labels(all_tx_te, all_id_te, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.join(\"..\", \"result\")\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "OUTPUT_PATH = '../result/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
